# -*- coding: utf-8 -*-
"""B2G5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rNICflImBrcvvPh1scw2HhgBWppRZHTJ

#Import all required libraries for reading data, analysing and visualizing data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model
from sklearn import metrics
from sklearn import ensemble
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error as MSE
from sklearn.metrics import mean_absolute_error as MAE
from sklearn.metrics import r2_score as r2
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import MinMaxScaler

"""Dataset"""

df = pd.read_csv('/content/Dataset.csv')

df

"""Converting Object values to Number values"""

df2=df
categorical_cols = ['Watch','Color','Compatible Device','Heart Rate Checker','GPS','Step Counter'] 

from sklearn.preprocessing import LabelEncoder
# instantiate labelencoder object
le = LabelEncoder()

# apply le on categorical feature columns
df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))

df2



"""Train the Dataset"""

X= df2.iloc[:,0:9].values
Y= df2.iloc[:,9:10].values

reg = linear_model.LinearRegression()

scale = StandardScaler()
X= scale.fit_transform(X)
Y= scale.fit_transform(Y)

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=.2,random_state=0)

reg.fit(X_train,Y_train)

"""**Linear Regression**"""

y_pred = reg.predict(X_test)
y_pred
mse_l = MSE(Y_test,y_pred)
print("Mean Squared Error of Linear Regression       : ",mse_l)
rmse_l = mse_l**(1/2)
print("Root Mean Squared Error of Linear Regression  : ",rmse_l)
mae_l = MAE(Y_test,y_pred)
print("Mean Absolute Error of Linear Regression      : ",mae_l)
rsquare_l = r2(Y_test,y_pred)
print("R_Square of Linear Regression                 : ",rsquare_l)
test_data_prediction=reg.predict(X_test)

"""**Polynomial Regression**"""

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2)
x_poly = poly.fit_transform(X_train)
poly.fit(X_train,Y_train)

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(x_poly,Y_train)

y_pred = model.predict(poly.fit_transform(X_test))
y_pred
mse_p = MSE(Y_test,y_pred)
print("Mean Squared Error of Polynomial Regression   : ",mse_p)
rmse_p = mse_p**(1/2)
print("Root Mean Squared Error of Linear Regression  : ",rmse_p) 
mae_p = MAE(Y_test,y_pred)
print("Mean Absolute Error of Polynomial Regression  : ",mae_p)
rsquare_p = r2(Y_test,y_pred)
print("R_Square of Polynomial Regression             : ",rsquare_p)

"""**Decision Tree Regression**"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error as MSE 

dt = DecisionTreeRegressor(max_depth=7,min_samples_leaf=0.1,random_state=0)
dt.fit(X_train,Y_train)
y_pred = dt.predict(X_test)
y_pred
mse_d = MSE(Y_test,y_pred)
print("Mean Squared Error of Decision Tree Regression  : ",mse_d)
rmse_d = mse_d**(1/2)
print("Root Mean Squared Error of Linear Regression    : ",rmse_d)
mae_d = MAE(Y_test,y_pred)
print("Mean Absolute Error of Decision Tree Regression : ",mae_d)
rsquare_d = r2(Y_test,y_pred)
print("R_Square of Decision Tree Regression            : ",rsquare_d)

"""**Bayesian Regression**"""

BayReg = linear_model.BayesianRidge()
BayReg.fit(X_train,Y_train.ravel())

y_pred = BayReg.predict(X_test)
y_pred

mse_b = MSE(Y_test,y_pred)
print("Mean Squared Error of Bayesian Regression     : ",mse_b)
rmse_b = mse_b**(1/2)
print("Root Mean Squared Error of Linear Regression  : ",rmse_d)
mae_b = MAE(Y_test,y_pred)
print("Mean Absolute Error of Bayesian Regression    : ",mae_b)
rsquare_b = r2(Y_test,y_pred)
print("R_Square of Bayesian Regression               : ",rsquare_b)

"""**Random Forrest Regression**"""

from sklearn.ensemble import RandomForestRegressor

RfReg = RandomForestRegressor(n_estimators=15, random_state=0)
RfReg.fit(X_train,Y_train.ravel())
y_pred = RfReg.predict(X_test)
y_pred
mse_r = MSE(Y_test,y_pred)
print("Mean Squared Error of Random Forest Regression   : ",mse_r)
rmse_r = mse_r**(1/2)
print("Root Mean Squared Error of Linear Regression     : ",rmse_r)
mae_r = MAE(Y_test,y_pred)
print("Mean Absolute Error of Random Forest Regression  : ",mae_r)
rsquare_r = r2(Y_test,y_pred)
print("R_Square of Random Forest Regression             : ",rsquare_r)

"""**Support Vector Regression**"""

from sklearn.svm import SVR
regressor = SVR(kernel = 'rbf')
regressor.fit(X_train,Y_train.ravel())

y_pred = regressor.predict(X_test)
y_pred

mse_s = MSE(Y_test,y_pred)
print("Mean Squared Error of Support Vector Regression  : ",mse_s)
rmse_s = mse_s**(1/2)
print("Root Mean Squared Error of Linear Regression     : ",rmse_s)
mae_s = MAE(Y_test,y_pred)
print("Mean Absolute Error of Support Vector Regression : ",mae_s)
rsquare_s = r2(Y_test,y_pred)
print("R_Square of Support Vector Regression            : ",rsquare_s)

"""# Comparison Between Models"""

x1 = np.array(["Linear", "Polynomial", "Decision Tree",
                               "Bayesian Ridge", "Random Forrest", "Support Vector"]) 
y1 = np.array([mae_l, mae_p, mae_d, mae_b, mae_r, mae_s])
x_pos = np.arange(len(x1))
plt.bar(x1, y1,color=['dimgrey', 'maroon', 'mediumseagreen', 'cyan', 'steelblue','purple'])
plt.xticks(x_pos, x1, rotation=90)
plt.xlabel("Models") #Y_train at x label
plt.ylabel("Mean Absolute Error") #predictedcalue at y label
plt.title("Models vs Mean Absolute Error")
plt.show()

"""Models vs Mean Squared Error"""

x1 = np.array(["Linear", "Polynomial", "Decision Tree",
                               "Bayesian Ridge", "Random Forrest", "Support Vector"]) 
y1 = np.array([mse_l, mse_p, mse_d, mse_b, mse_r, mse_s])
x_pos = np.arange(len(x1))
plt.bar(x1, y1,color=['dimgrey', 'maroon', 'mediumseagreen', 'cyan', 'steelblue','purple'])
plt.xticks(x_pos, x1, rotation=90)
plt.xlabel("Models") 
plt.ylabel("Mean Squared Error") 
plt.title("Models vs Mean Squared Error")
plt.show()

"""Models vs Root Mean Squared Error"""

x1 = np.array(["Linear", "Polynomial", "Decision Tree",
                               "Bayesian Ridge", "Random Forrest", "Support Vector"]) 
y1 = np.array([rmse_l, rmse_p, rmse_d, rmse_b, rmse_r, rmse_s])
x_pos = np.arange(len(x1))
plt.bar(x1, y1,color=['dimgrey', 'maroon', 'mediumseagreen', 'cyan', 'steelblue','purple'])
plt.xticks(x_pos, x1, rotation=90)
plt.xlabel("Models") #Y_train at x label
plt.ylabel("Root Mean Squared Error") #predictedcalue at y label
plt.title("Models vs Root Mean Squared Error")
plt.show()

"""Models vs R Squared Error"""

x1 = np.array(["Linear", "Polynomial", "Decision Tree",
                               "Bayesian Ridge", "Random Forrest", "Support Vector"]) 
y1 = np.array([rsquare_l, rsquare_p, rsquare_d, rsquare_b, rsquare_r, rsquare_s])
x_pos = np.arange(len(x1))
plt.bar(x1, y1,color=['dimgrey', 'maroon', 'mediumseagreen', 'cyan', 'steelblue','purple'])
plt.xticks(x_pos, x1, rotation=90)
plt.xlabel("Models") #Y_train at x label
plt.ylabel("R-Squared  Error") #predictedcalue at y label
plt.title("Models vs R Squared Error")
plt.show()